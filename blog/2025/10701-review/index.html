<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Course review --- CMU 10701 | Runqiu Ye </title> <meta name="author" content="Runqiu Ye"> <meta name="description" content="Course review and reflection on CMU 10701, introduction to machine learning (PhD)"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8D%94&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://runqiuye.github.io/blog/2025/10701-review/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Runqiu</span> Ye </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Course review --- CMU 10701</h1> <p class="post-meta"> Created on May 29, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/computer-science"> <i class="fa-solid fa-hashtag fa-sm"></i> computer science</a>   <a href="/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> machine learning</a>   ·   <a href="/blog/category/review"> <i class="fa-solid fa-tag fa-sm"></i> review</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>I was going to play some basketball in UW, but the court is taken by some club tournament. Therefore here I am writing this course review on CMU 10701, introduction to machine learning (PhD). As a comparison, I will mention another relevant course I self-studied — Stanford CS229, also introduction to machine learning.</p> <p>I self studied Stanford CS229 during Summer 2024. I think it took me at least half of summer to watch all the lectures (2018 version) and complete all the assignments. I was also doing research at that time, even though that is a relatively stress-free hustle. I took CMU 10701 in Spring 2025, with instructors being Professor Geoffery Gordon and Professor Max Simchowitz. One thing I need to point out is that I registered for this class with time conflict. I did not attend any lectures except for the ones that are midterm and final. However there are lecture recordings so I watched some of them, or actually I think most of them.</p> <p>Overall, I would rate the quality of the class about 6.5 out of 10. As a comparison, I would rate the quality of Stanford CS229 9.5 out of 10, again this is the 2018 version of the course. Even though I don’t really care who the professor is as I mentioned before, the teaching of this course, at least this semester, is horrible. Even though by no means am I trying to say the instructors do not know their stuff for machine learning, they are really not good teachers. Professor Gordon has been teaching this class for many years as far as I know, and he is also probably one of the oldest people in this school that has taken 10701. His lectures usually are a partially completed slides, while he fills it out using a tablet. The slide are by no means good, featuring long sentences that hardly grab attention. The handwritten part are also quite hard to understand. On the other hand, it’s probably Professor Simchowitz’s probably first time teaching any course. His lectures usually feature a slide with many typos, which he claims will be fixed after lecture and usually the typos are still there when I download them after two days of the lecture. He also has a huge ego, like to mention random terms and complicated concepts that are unnecessary. As a comparison, Stanford CS229 features Andrew Ng as the instructor. He always write on the board directly. The lectures are well organized and well structured, with natural mathematical calculations and providing deep insights into the topics. I guess this is a combination of good lecture style and good course material, which is something I will talk about next.</p> <p>The course material of CMU 10701 are good and bad at the same time. We shall compare the course material of both. As expected for an introduction to machine learning class, linear regression, logistic regression, kernels and SVMs, deep learning basics, PCA, and reinforcement learning basics are covered. There are quite a few notable differences. First for CMU 10701, it covers convolutional networks (CNN), recurrent neural networks (RNN), attentions and transformers in LECTURE. Considering the fact that the Stanford class I watched is 2018, we cannot really say much about this. CMU 10701 also covers some basic learning theory (PAC learning and VC dimension), and some introduction to graphical models. These are not covered by the Stanford class, and that’s why I say the course material is good. The CNN, RNN, attention and transformers class are no doubt great introduction to more advanced deep learning class, and classes that focus more on computer vision or natural language processing. The graphical models part also improves my feelings toward the class by a lot, as I like probability and things on the theory side. Therefore I find this really interesting We must note here though by “course material is good”, I do not mean “their presentation of this material is good”. It’s more like it gives me a chance to learn more about these by myself, which turns out to be really interesting. The only exception of this is the one assignment that requires us to implement RNN and transformer encoder using PyTorch. I learned PyTorch from this, and the implementation process improves my understanding of these. However all the materials I referenced while during the homework is either slides for Stanford CS224n (Natural Language Processing), or the paper <em>Attention is all you need</em> itself, instead of the lecture slides. For graphical models, the assignment again help me understand variable elimnation better, but the real click is when I read Bishop’s Patter Recognition and Machine Learning (PRML) book. It gives a more structured introduction to hidden Markov models and graphical models, while generalizing the stuff covered in class into the stage where I feel very interested in. That’s also partially why I will take 10708 probabilistic graphical models next semester. I hope it will give me the chance of reading more of this book. Without this transformer homework and the graphical model part of the course I would probably just give a 5 out of 10 for this class.</p> <p>Now why is the course material bad? Seemingly the Stanford CS229 covers less material, but I think the organization of material is much better. Let’s see an example. Both class covered this thing called the Variational Auto-encoder (VAE) and some basics of diffusion models, in the unsupervised learning section. In 10701, this seems like a very separated lecture called “generative AI”, after talking about contrastive learning and PCA which I don’t think is quite relevant to this. In CS229 this is not in the lectures but in the notes as an optional material, but the way this get introduced is much more natural. For unsupervised learning, CS229 talked about k-means, PCA, ICA. But the difference maker is this thing called the mixture of Gaussians and Expectation Maximization (EM). In my opinion EM is the single most important thing for the theory of probabilistic methods, and VAE precisely utilized the generalized EM algorithm. Generalized EM is also everywhere in PRML. Relevant to this is some lower bound of a distribution called ELBO. CS229 introduces this ELBO through Jensen’s inequality, and take this to a further step through KL divergence in homework. In comparison, 10701 pulls this lower bound out of nowhere using a Taylor’s expansion in a weird form hidden in Professor Gordon’s squibble. This in my opinion is very unnatural, and the funniest part is they put the KL divergence understanding on the finals. In my opinion EM is the key of understand VAE and diffusion models, and I am pretty sure minimal amount of people actually understand what is covered in the generative AI lecture, and surprise surprise this section contribute to another huge part of the final.</p> <p>The RL section is another perfect example for this. Seemingly both classes covered basics of RL, but 10701 only covers the dynamic programming approach to finite horizon MDP. In contrast, CS229 introduces value interation and policy interation using Bellman equation, and in homework we PROVED Bellman update oprator that are used in value iteration is a CONTRACTION MAP! If this is unfamiliar to you, this mean there is a fixed point in the space, and in this case the optimal policy. This gives the correctness of the algorithms and I personally think this is very exciting. DP approach for finite horizon MDP is of course also covered and there are so much more in the notes. Therefore I cannot help but think — why can’t 10701 reduces the introduction of unnecessary random terms, but actually covers the content more in depth? Similarly, topics like contrastive learning simply doesn’t fit into this intro course, but it ended up taking another huge part of the final.</p> <p>One other difference of the two courses is the homework. CS229 only allows NumPy, no PyTorch. I don’t think this is better or worse, but I think this shows the more emphasis on actually understanding the mathematics behind every algorithm, and in the end we implemented a simple CNN for handwritten digit classification, using only NumPy including the back propogation. However again I like transformer part of homework in 10701, as I already said. Also I am not definitely complaining learning PyTorch, which is definitely something I should know, through this chance.</p> <p>I guess that’s it for my comment on these two classes. Overall I think CS229 gives a much better foundational understanding for these introductory machine learning concepts, the homework also gives insights on both the math and the hands-on. The math part of CS229 definitely stands out much more through both lectures and homework. For a side note, I cannot give any advice on the selection between 10301 and 10701, because I have never taken 10301. I also never considered it because before this semester 10301 does not count for major and I want to use 10701 as a prerequisite for a lot more graduate machine learning class.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/super-egg-drop/">Super Egg Drop</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/15210-review/">Course review --- CMU 15210</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/summary/">Two weeks of summer --- summary and reflection</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/setup/">Setting up this website</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/numdp/">Counting numbers</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Runqiu Ye. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>